{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vic_electricity\n",
      "---------------\n",
      "Half-hourly electricity demand for Victoria, Australia\n",
      "O'Hara-Wild M, Hyndman R, Wang E, Godahewa R (2022).tsibbledata: Diverse\n",
      "Datasets for 'tsibble'. https://tsibbledata.tidyverts.org/,\n",
      "https://github.com/tidyverts/tsibbledata/.\n",
      "https://tsibbledata.tidyverts.org/reference/vic_elec.html\n",
      "Shape of the dataset: (52608, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arzua\\AppData\\Local\\Temp\\ipykernel_1468\\558530577.py:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  datos = datos.resample(rule='H', closed='left', label='right').mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== \n",
      "ForecasterEquivalentDate \n",
      "======================== \n",
      "Offset: <DateOffset: days=1> \n",
      "Number of offsets: 1 \n",
      "Aggregation function: mean \n",
      "Window size: 24 \n",
      "Training range: [Timestamp('2012-01-01 00:00:00'), Timestamp('2014-11-30 23:00:00')] \n",
      "Training index type: DatetimeIndex \n",
      "Training index frequency: h \n",
      "Creation date: 2024-06-06 07:59:05 \n",
      "Last fit date: 2024-06-06 07:59:05 \n",
      "Skforecast version: 0.12.1 \n",
      "Python version: 3.11.7 \n",
      "Forecaster id: None \n",
      "\n",
      "================= \n",
      "ForecasterAutoreg \n",
      "================= \n",
      "Regressor: LGBMRegressor(random_state=15926, verbose=-1) \n",
      "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "Transformer for y: None \n",
      "Transformer for exog: None \n",
      "Window size: 24 \n",
      "Weight function included: False \n",
      "Differentiation order: None \n",
      "Exogenous included: False \n",
      "Type of exogenous variable: None \n",
      "Exogenous variables names: None \n",
      "Training range: [Timestamp('2012-01-01 00:00:00'), Timestamp('2014-11-30 23:00:00')] \n",
      "Training index type: DatetimeIndex \n",
      "Training index frequency: h \n",
      "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 15926, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
      "fit_kwargs: {} \n",
      "Creation date: 2024-06-06 07:59:05 \n",
      "Last fit date: 2024-06-06 07:59:06 \n",
      "Skforecast version: 0.12.1 \n",
      "Python version: 3.11.7 \n",
      "Forecaster id: None \n",
      "\n",
      "================= \n",
      "ForecasterAutoreg \n",
      "================= \n",
      "Regressor: LGBMRegressor(random_state=15926, verbose=-1) \n",
      "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "Transformer for y: None \n",
      "Transformer for exog: None \n",
      "Window size: 24 \n",
      "Weight function included: False \n",
      "Differentiation order: None \n",
      "Exogenous included: True \n",
      "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
      "Exogenous variables names: ['Temperature', 'Holiday'] \n",
      "Training range: [Timestamp('2012-01-01 00:00:00'), Timestamp('2014-11-30 23:00:00')] \n",
      "Training index type: DatetimeIndex \n",
      "Training index frequency: h \n",
      "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 15926, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
      "fit_kwargs: {} \n",
      "Creation date: 2024-06-06 07:59:06 \n",
      "Last fit date: 2024-06-06 07:59:06 \n",
      "Skforecast version: 0.12.1 \n",
      "Python version: 3.11.7 \n",
      "Forecaster id: None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterBaseline import ForecasterEquivalentDate\n",
    "from skforecast.datasets import fetch_dataset\n",
    "\n",
    "# Directorio donde se guardarán y cargarán los modelos\n",
    "save_dir = 'C:\\\\Users\\\\arzua\\\\OneDrive\\\\Escritorio\\\\preelec\\\\src\\\\'\n",
    "\n",
    "# Cargar datos\n",
    "datos = fetch_dataset(name='vic_electricity', raw=True)\n",
    "datos['Time'] = pd.to_datetime(datos['Time'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "datos = datos.set_index('Time')\n",
    "datos = datos.asfreq('30min')\n",
    "datos = datos.sort_index()\n",
    "datos = datos.drop(columns='Date')\n",
    "datos = datos.resample(rule='H', closed='left', label='right').mean()\n",
    "datos = datos.loc['2012-01-01 00:00:00': '2014-12-30 23:00:00'].copy()\n",
    "fin_train = '2013-12-31 23:59:00'\n",
    "fin_validacion = '2014-11-30 23:59:00'\n",
    "datos_train = datos.loc[:fin_train, :].copy()\n",
    "datos_val = datos.loc[fin_train:fin_validacion, :].copy()\n",
    "datos_test = datos.loc[fin_validacion:, :].copy()\n",
    "\n",
    "# Crear y entrenar el modelo baseline\n",
    "forecaster_baseline = ForecasterEquivalentDate(\n",
    "    offset=pd.DateOffset(days=1),\n",
    "    n_offsets=1\n",
    ")\n",
    "forecaster_baseline.fit(y=datos.loc[:fin_validacion, 'Demand'])\n",
    "\n",
    "# Crear y entrenar el modelo autoregresivo recursivo\n",
    "forecaster_autoreg = ForecasterAutoreg(\n",
    "    regressor=LGBMRegressor(random_state=15926, verbose=-1),\n",
    "    lags=24\n",
    ")\n",
    "forecaster_autoreg.fit(y=datos.loc[:fin_validacion, 'Demand'])\n",
    "\n",
    "# Crear y entrenar el modelo autoregresivo recursivo con variables exógenas\n",
    "# Para simplicidad, las variables exógenas se generan de manera arbitraria.\n",
    "# En un caso real, deberías definir tus variables exógenas según el problema.\n",
    "exog_features = ['Temperature', 'Holiday']\n",
    "forecaster_autoreg_exog = ForecasterAutoreg(\n",
    "    regressor=LGBMRegressor(random_state=15926, verbose=-1),\n",
    "    lags=24\n",
    ")\n",
    "forecaster_autoreg_exog.fit(\n",
    "    y=datos.loc[:fin_validacion, 'Demand'],\n",
    "    exog=datos.loc[:fin_validacion, exog_features]\n",
    ")\n",
    "\n",
    "# Guardar los modelos entrenados\n",
    "joblib.dump(forecaster_baseline, save_dir + 'forecaster_baseline.pkl')\n",
    "joblib.dump(forecaster_autoreg, save_dir + 'forecaster_autoreg.pkl')\n",
    "joblib.dump(forecaster_autoreg_exog, save_dir + 'forecaster_autoreg_exog.pkl')\n",
    "\n",
    "# Cargar los modelos entrenados\n",
    "forecaster_baseline_loaded = joblib.load(save_dir + 'forecaster_baseline.pkl')\n",
    "forecaster_autoreg_loaded = joblib.load(save_dir + 'forecaster_autoreg.pkl')\n",
    "forecaster_autoreg_exog_loaded = joblib.load(save_dir + 'forecaster_autoreg_exog.pkl')\n",
    "\n",
    "# Comprobar que los modelos cargados funcionan correctamente\n",
    "print(forecaster_baseline_loaded)\n",
    "print(forecaster_autoreg_loaded)\n",
    "print(forecaster_autoreg_exog_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_elec_1)",
   "language": "python",
   "name": "nombre_del_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
